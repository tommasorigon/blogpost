---
title: "Karmic dice for Baldur's Gate III"
subtitle: "A probabilistic perspective"
author: "[Tommaso Rigon]{.orange}"
lang: en
date: 2023-08-20
execute:
  cache: true
format:
  html:
    html-math-method: katex
    echo: true
    callout-appearance: minimal
    theme: [cosmo, ../template.css]
    toc: false
    embed-resources: true
    code-line-numbers: true
    smooth-scroll: true
    fig-dpi: 250
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

## Karmic dice: what do they do?

I played the game "Baldur's Gate" when I was a kid, on my old-fashioned
computer, and I thought it was a great game. When [Baldur's Gate
III](https://baldursgate3.game) was released a few weeks ago, it caught
my attention.

The main dynamics of the game are based on Dungeons & Dragons, which
means that players need to roll the famous [20 sided dice]{.orange}
several times. On a laptop / console, the ["random" numbers]{.blue}
(actually, pseudo-random) are automatically generated by the software.

A specific feature of the game was very much discussed by the online
community: the [karmic
dice](https://www.ign.com/wikis/baldurs-gate-3/Karmic_Dice_Explained).

The main principle of a karmic dice is that it should [avoid
subsequent]{.blue} successes and [failures]{.blue}. In other terms, the
results of the dice are [not independent]{.orange} anymore!

I am an Assistant Professor in Statistics, so I had a few questions in
my mind: how does this algorithm
work, exactly? Will it preserve basic properties that do not [screw
up]{.blue} the balance of the game?

#### Regular dice vs karmic dice

```{r}
#| echo: false
rm(list = ls())
karmic_score <- function(n, kappa) {
  sigma <- sqrt(1 / (1 - kappa^2))
  latent_score <- numeric(n)
  latent_score[1] <- rnorm(1, 0, sigma)
  for (i in 1:(n - 1)) {
    latent_score[i + 1] <- -kappa * latent_score[i] + rnorm(1, 0, 1)
  }
  latent_score
}
```

```{r}
#| echo: false
karmic_dice <- function(n, kappa) {
  sigma <- sqrt(1 / (1 - kappa^2))
  latent_score <- karmic_score(n, kappa)
  ceiling(20 * pnorm(latent_score, 0, sigma))
}
```

Let us step back for a second. Why do we need a karmic dice in the first
place?

Most people find "[true randomness]{.orange}" (independent trials) quite
[counterintuitive]{.orange}.

Suppose we toss the a fair dice with 20 sides, say, 100 times. A
compatible sequence of results could be:

```{r}
#| echo: false
set.seed(50)
karmic_dice(n = 100, kappa = 0)
```

A surprising amount of people would find this sequence "non-random" or
would suspect that something is off with the random number generator
(RNG). There is indeed a sequence of bad rolls:
`7, 8, 9, 5, 3, 8, 8, 6`, and `2`. Is this some kind of mistake?

Long story short: there is nothing fishy going on, this is just the
normal behavior of a regular dice. Yet, a non-trained eye would expect
something like the following [karmic sequence]{.blue} (dependent
trials):

```{r}
#| echo: false
set.seed(60)
karmic_dice(n = 100, kappa = 0.35)
```

In this sequence, there are less streaks of negative results and many
players find this kind of pattern more enjoyable.

#### The long-run behavior and weighted dices

There are many ways to obtain a sequence with less unlucky rolls. A 
simple idea could be using a [weighted dice]{.orange}, e.g. an hypothetical
dice with non-uniform probabilities.

Such a weighted dice accomplishes the goal of reducing extreme events, but it is modifying a fundamental aspect of Dungeons & Dragons and therefore affecting the [balance of the game]{.orange}. 

Changing the rules is not necessarily a bad thing, but it has consequences. Indeed, most role players are well-aware that there is a difference between [1d20]{.blue} and [2d10]{.orange}.

#### Desiderata for a karmic dice

I think a more [gentle approach]{.blue} would be tweaking the algorithm in such a way:
  
  - The [long-rung proportions]{.blue} are identical to those of a regular dice, i.e. each side of the dice has a $5\%$ probability of being picked if we were to roll the dice a huge amount of times.
  
  - The rolls are [dependent]{.orange}, meaning the the values obtained at the previous step influence the future behavior. 

Moreover, the algorithm should be easy to implement and modify, to account for players preferences (e.g. weak vs strong karma effect). 

## A simple algorithm for the karmic dice

How do we construct an algorithm with the above properties? I do not know which approach is implemented in Baldur's Gate III, I can only make educated guesses. However, it turns out that the there exist a simple solution, which is based on the notion of [latent karma]{.blue}.

Let us focus on the generic $t$th roll. The latent karma $Y_t$ of the is a real number that identifies how lucky we have been, say the [positive]{.blue} values $1.5$ or $3.2$ (lucky events) or the [negative]{.orange} value $-4.3$ (unlucky event).

Let $0 < \kappa < 1$ be a constant that determines the "karma effect". The [first]{.blue} karma score $Y_1$ does not depend on the past (because there is no past) and we generate it according to a Gaussian random variable: 

$$
Y_1 \sim N\left(0, \frac{1}{1 - \kappa^2}\right).
$$ 

The subsequent karma scores are obtained by adjusting the previous karma score as follows:

$$
Y_t = - \kappa \:Y_{t-1} + \epsilon_t, \qquad \epsilon_t \sim \text{N}(0, 1),
$$
for $t = 2,\dots,n$. In other words, if we were unlucky at step $t$, we had better chances to be lucky at step $t+1$ (and vice-versa). The amount of this effect is regulated by $\kappa$.

In R code, the generation of the latent karma scores is straightforward:

```{r}
karmic_score <- function(n, kappa) {
  sigma <- sqrt(1 / (1 - kappa^2))
  latent_score <- numeric(n)
  
  # First latent karma Y_1
  latent_score[1] <- rnorm(1, 0, sigma)
  
  # Generation of the latent karma values Y_2,...,Y_n
  for (t in 1:(n - 1)) {
    latent_score[t + 1] <- -kappa * latent_score[t] + rnorm(1, 0, 1)
  }
  
  return(latent_score)
}
```

Once we have obtained the karma scores $Y_t$, we simply [convert]{.orange} them into integers $D_t$, belonging to $1,\dots,20$, using the following formula

$$
D_t = \text{ceiling}\{20 \Phi_\kappa(Y_t)\}, \qquad t = 1,\dots,n,
$$
where $\Phi_\kappa(y)$ is the [cumulative distribution function]{.blue} of a Gaussian with zero mean and variance $1 / (1 - \kappa^2)$. The $\text{ceiling}$ operation rounds up its argument, producing an integer. Once again, this operation can be performed with a few lines of R code.

```{r}
karmic_dice <- function(n, kappa) {
  sigma <- sqrt(1 / (1 - kappa^2))
  
  # Generate the latent scores
  latent_score <- karmic_score(n, kappa)
  # Convert the latent scores into integers between 1 and 20
  dice_results <- ceiling(20 * pnorm(latent_score, 0, sigma))
  return(dice_results)
}
```

## Analyzing the algorithm

The main interesting property of this karmic dice is that is preserves the long-run proportions. If you are familiar with the theory of [auto-regressive processes]{.blue} and the so-called [inversion theorem]{.orange} for generting random variables, this should be immediately obvious to you. 

If not, as it is more than likely, I will try to convince you with an empirical demonstration. What if I make 1 million rolls and check how many times I got each of the values $1,2,\dots, 20$?

Well, with a computer, this can be easily done (using $\kappa = 0.35$) and this is what we get

```{r}
# cache: true
table(karmic_dice(10^6, kappa = 0.35)) / 10^6
```

Each number is roughly appearing in the sequence $5\%$ of the times, as it should!


```{r}
#| cache: true
#| echo: false
n <- 5 * 10^6
kappa <- c(0, 0.35, 0.55)
sim1 <- karmic_dice(n = n, kappa = kappa[1])
sim2 <- karmic_dice(n = n, kappa = kappa[2])
sim3 <- karmic_dice(n = n, kappa = kappa[3])

tab1 <- table(sim1[1:(n - 1)], sim1[2:n])
tab1 <- tab1 / rowSums(tab1)

tab2 <- table(sim2[1:(n - 1)], sim2[2:n])
tab2 <- tab2 / rowSums(tab2)

tab3 <- table(sim3[1:(n - 1)], sim3[2:n])
tab3 <- tab3 / rowSums(tab3)
```

```{r}
#| echo: false
library(ggplot2)
df <- rbind(data.frame(reshape2::melt(tab2), kappa = "Karmic dice (kappa = 0.35)"))
ggplot(df, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "black") +
  scale_fill_gradient2(low = "#fc7d0b", high = "#1170aa", midpoint = 0.05, mid = "white") +
  coord_fixed() +
  facet_grid(. ~ kappa) +
  scale_x_continuous(breaks = 1:20, minor_breaks = NULL) +
  scale_y_continuous(breaks = 1:20, minor_breaks = NULL) +
  theme_bw() +
  guides(fill = guide_colourbar(title = "Probability")) +
  xlab("Current roll") +
  ylab("Next roll")
```


